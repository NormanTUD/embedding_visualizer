<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Interactive Tokenizer + Embedding Visualizer</title>

<style>
body {
    margin: 0;
    font-family: Arial, sans-serif;
    background: #0f172a;
    color: #e2e8f0;
    display: flex;
    flex-direction: column;
    height: 100vh;
}

header {
    padding: 12px;
    background: #020617;
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
}

section {
    flex: 1;
    padding: 10px;
    overflow: auto;
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 10px;
}

textarea, select, input, button {
    background: #020617;
    border: 1px solid #334155;
    color: #f8fafc;
    padding: 6px;
    border-radius: 4px;
    font-size: 13px;
}

textarea {
    width: 100%;
    min-height: 90px;
    resize: vertical;
}

button {
    cursor: pointer;
}

#plot {
    grid-column: span 2;
    height: 100%;
    border: 1px solid #334155;
    border-radius: 4px;
}

#status-bar {
    background: #020617;
    padding: 6px 12px;
    font-size: 12px;
    border-top: 1px solid #334155;
    color: #38bdf8;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
}

fieldset {
    border: 1px solid #334155;
    border-radius: 6px;
    padding: 8px;
}

legend {
    padding: 0 6px;
    font-size: 13px;
    color: #7dd3fc;
}
</style>
</head>

<body>
<header>
    <fieldset>
        <legend>Tokenizer</legend>
        <select id="tokenizerType">
            <option value="space">Space</option>
            <option value="comma">Comma</option>
            <option value="ngram">N-Gram</option>
            <option value="char">Character</option>
        </select>
        <input id="ngramN" type="number" value="2" min="1">
        <button id="btnTokenize">Tokenize</button>
    </fieldset>

    <fieldset>
        <legend>Embedding</legend>
        <input id="embedDim" type="number" value="2" min="1">
        <input id="learningRate" type="number" step="0.001" value="0.01">
        <input id="epochs" type="number" value="20">
        <button id="btnTrain">Train</button>
    </fieldset>

    <fieldset>
        <legend>Tests</legend>
        <button id="btnRunTests">Run All Tests</button>
    </fieldset>
</header>

<section>
    <div>
        <h3>Training Text</h3>
        <textarea id="trainText">This is a simple example text for embeddings</textarea>
    </div>

    <div>
        <h3>Probe Text</h3>
        <textarea id="probeText">simple example</textarea>
    </div>

    <div id="plot"></div>
</section>

<div id="status-bar">Ready</div>

<script src="tf.min.js"></script>
<script src="plotly.latest.js"></script>

<script>
"use strict";

(function(){

let state = {
    tokens: [],
    vocab: new Map(),
    reverse: [],
    model: null,
    embedDim: 2
};

function log(msg, type) {
    let bar = document.getElementById("status-bar");
    bar.textContent = msg;

    if (type === "error") console.error(msg);
    else if (type === "warn") console.warn(msg);
    else if (type === "debug") console.debug(msg);
    else console.log(msg);
}

/* ================== TOKENIZERS =================== */

function tokenize(text, type, n) {
    console.group("Tokenizer");
    let tokens = [];

    if (type === "space") {
        tokens = text.trim().split(/\s+/);
    }

    if (type === "comma") {
        tokens = text.split(",").map(s => s.trim()).filter(Boolean);
    }

    if (type === "char") {
        tokens = text.replace(/\s+/g, "").split("");
    }

    if (type === "ngram") {
        let raw = text.trim().split(/\s+/);
        for (let i = 0; i + n <= raw.length; i++) {
            tokens.push(raw.slice(i, i + n).join("_"));
        }
    }

    console.debug("Tokens:", tokens);
    console.groupEnd();
    return tokens;
}

/* ================= VOCAB BUILDER ================= */

function buildVocab(tokens) {
    console.group("Vocabulary");
    state.vocab.clear();
    state.reverse = [];

    tokens.forEach(tok => {
        if (!state.vocab.has(tok)) {
            state.vocab.set(tok, state.reverse.length);
            state.reverse.push(tok);
        }
    });

    console.log("Vocab size:", state.reverse.length);
    console.groupEnd();
}

function encode(tokens) {
    let arr = [];
    tokens.forEach(t => {
        if (state.vocab.has(t)) {
            arr.push(state.vocab.get(t));
        }
    });
    return arr;
}

/* ================= MODEL ================= */

function createModel(vocabSize, embedDim, lr) {
    console.group("Creating model");

    let model = tf.sequential();

    model.add(
        tf.layers.embedding({
            inputDim: vocabSize,
            outputDim: embedDim,
            inputLength: 1
        })
    );

    model.add(tf.layers.flatten());

    model.compile({
        optimizer: tf.train.adam(lr),
        loss: "meanSquaredError"
    });

    console.log("Model built with vocab:", vocabSize, "dim:", embedDim);
    console.groupEnd();
    return model;
}

/* ================= PCA (PURE JS) ================ */

function computePCA(matrix, k) {
    console.group("PCA");

    // mean center
    let mean = [];
    for (let j = 0; j < matrix[0].length; j++) {
        let sum = 0;
        for (let i = 0; i < matrix.length; i++) sum += matrix[i][j];
        mean[j] = sum / matrix.length;
    }

    let centered = matrix.map(row =>
        row.map((v, i) => v - mean[i])
    );

    let cov = [];
    for (let i = 0; i < centered[0].length; i++) {
        cov[i] = [];
        for (let j = 0; j < centered[0].length; j++) {
            let sum = 0;
            for (let n = 0; n < centered.length; n++) {
                sum += centered[n][i] * centered[n][j];
            }
            cov[i][j] = sum / (centered.length - 1);
        }
    }

    function multiply(a, b) {
        let r = Array(a.length).fill(0).map(()=>Array(b[0].length).fill(0));
        for (let i = 0; i < a.length; i++)
            for (let j = 0; j < b[0].length; j++)
                for (let n = 0; n < a[0].length; n++)
                    r[i][j] += a[i][n] * b[n][j];
        return r;
    }

    let vectors = [];
    for (let i = 0; i < k; i++) {
        let v = Array(cov.length).fill(1);
        for (let iter = 0; iter < 100; iter++) {
            let mv = [];
            for (let r = 0; r < cov.length; r++) {
                let sum = 0;
                for (let c = 0; c < cov.length; c++) sum += cov[r][c] * v[c];
                mv[r] = sum;
            }
            let norm = Math.sqrt(mv.reduce((a,b)=>a+b*b,0));
            v = mv.map(x => x / norm);
        }
        vectors.push(v);
    }

    let result = multiply(centered, vectors.map(v=>[v]).flat());
    console.groupEnd();
    return result;
}

/* ================= PLOT ================= */

function plotEmbeddings(embeddings) {
    console.group("Plot");

    let xs = [], ys = [], zs = [], labels = [];

    embeddings.forEach((e, i) => {
        xs.push(e[0] || 0);
        ys.push(e[1] || 0);
        zs.push(e[2] || 0);
        labels.push(state.reverse[i]);
    });

    let trace = {};
    if (state.embedDim === 1) {
        trace = { x: xs, type:"scatter", mode:"markers+text", text: labels };
    } else if (state.embedDim === 2) {
        trace = { x: xs, y: ys, type:"scatter", mode:"markers+text", text: labels };
    } else {
        trace = { x: xs, y: ys, z: zs, type:"scatter3d", mode:"markers+text", text: labels };
    }

    let layout = {
        paper_bgcolor: "rgba(0,0,0,0)",
        plot_bgcolor: "rgba(0,0,0,0)",
        font: { color: "#e2e8f0" },
        margin: { t:10, l:10, r:10, b:10 }
    };

    Plotly.newPlot("plot", [trace], layout, {responsive:true});
    console.groupEnd();
}

/* ================= TRAIN ================= */

async function train() {
    console.group("Training");

    let text = document.getElementById("trainText").value;
    let type = document.getElementById("tokenizerType").value;
    let n = parseInt(document.getElementById("ngramN").value);
    let dim = parseInt(document.getElementById("embedDim").value);
    let lr = parseFloat(document.getElementById("learningRate").value);
    let epochs = parseInt(document.getElementById("epochs").value);

    state.embedDim = dim;

    let tokens = tokenize(text, type, n);
    buildVocab(tokens);

    let encoded = encode(tokens);

    let xs = tf.tensor2d(encoded, [encoded.length, 1]);
    let ys = tf.randomUniform([encoded.length, dim]);

    state.model = createModel(state.reverse.length, dim, lr);

    await state.model.fit(xs, ys, {
        epochs: epochs,
        callbacks: {
            onEpochEnd: async function(epoch){
                log("Epoch: " + epoch);
                let weights = state.model.layers[0].getWeights()[0].arraySync();
                if (dim > 3) {
                    let reduced = computePCA(weights, 3);
                    plotEmbeddings(reduced);
                } else {
                    plotEmbeddings(weights);
                }
            }
        }
    });

    console.groupEnd();
}

/* ================= TESTS ================= */

function runTests() {
    console.group("Tests");

    try {
        let t1 = tokenize("a b c", "space", 2);
        console.assert(t1.length === 3, "Space tokenizer failed");
        console.log("Tokenizer whitespace -> PASS");

        let t2 = tokenize("a b c", "ngram", 2);
        console.assert(t2.length === 2, "Ngram tokenizer failed");
        console.log("Tokenizer ngram -> PASS");

        buildVocab(["a","b","c"]);
        let enc = encode(["a","b"]);
        console.assert(enc.length === 2, "Encoding failed");
        console.log("Vocab build & encode -> PASS");

        let m = createModel(5,2,0.01);
        console.assert(m != null, "Model build failed");
        console.log("Model creation -> PASS");

        console.log("All tests passed");

    } catch(e) {
        console.error(e);
        console.warn("Test failed");
    }

    console.groupEnd();
}

/* ================== INIT ================= */

function init() {
    document.getElementById("btnTokenize").onclick = ()=> {
        let txt = document.getElementById("trainText").value;
        let type = document.getElementById("tokenizerType").value;
        let n = parseInt(document.getElementById("ngramN").value);

        let t = tokenize(txt, type, n);
        buildVocab(t);
        log("Tokenized: "+t.length);
    };

    document.getElementById("btnTrain").onclick = train;
    document.getElementById("btnRunTests").onclick = runTests;

    log("Ready");
}

window.onload = init;

})();
</script>
</body>
</html>
