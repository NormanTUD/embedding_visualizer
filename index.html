<!doctype html>
<html lang="de">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Interactive Tokenizer → Embedding Trainer (didactic)</title>

  <script src="./tf.min.js"></script>
  <script src="./plotly.latest.js"></script>

  <style>
    :root {
      --bg: #071325;
      --panel: rgba(255,255,255,0.03);
      --muted: #9aa4b2;
      --accent: #5eead4;
      --card-shadow: 0 8px 24px rgba(2,6,23,0.6);
      --radius: 12px;
      --mono: ui-monospace, SFMono-Regular, Menlo, Monaco, "Roboto Mono", "Courier New", monospace;
    }
    html,body { height:100%; margin:0; font-family:Inter,system-ui, -apple-system, "Segoe UI", Roboto, Arial; background: linear-gradient(180deg,#04121b,#071325); color:#e6eef6; -webkit-font-smoothing:antialiased; }
    .container { max-width:1200px; margin:20px auto 120px; padding:16px; display:grid; grid-template-columns: 1fr 420px; gap:16px; }
    header { display:flex; align-items:center; justify-content:space-between; gap:12px; margin-bottom:12px; }
    .brand { display:flex; gap:12px; align-items:center; }
    .logo { width:48px;height:48px;border-radius:10px;background:linear-gradient(135deg,var(--accent),#60a5fa);display:flex;align-items:center;justify-content:center;font-weight:700;color:#04293a; box-shadow: 0 6px 18px rgba(0,0,0,0.5); }
    h1 { font-size:18px; margin:0; }
    p.lead { margin:0; font-size:12px; color:var(--muted); }
    .panel { background:var(--panel); border-radius:var(--radius); box-shadow:var(--card-shadow); padding:12px; overflow:hidden; }
    .panel.small { padding:8px; }
    label { display:block; font-size:12px; color:var(--muted); margin-bottom:6px; }
    textarea, input, select { width:100%; padding:8px 10px; border-radius:8px; border:1px solid rgba(255,255,255,0.04); background:transparent; color:inherit; font-size:13px; box-sizing:border-box; outline:none; resize:vertical; min-height:40px; }
    .grid { display:grid; gap:8px; }
    .controls { display:flex; gap:8px; flex-wrap:wrap; }
    button { background:linear-gradient(180deg,#60a5fa,var(--accent)); color:#04293a; border:none; padding:8px 12px; border-radius:8px; cursor:pointer; font-weight:600; box-shadow: 0 6px 16px rgba(5,9,20,0.6); }
    button.ghost { background:transparent;color:var(--accent); border:1px solid rgba(255,255,255,0.04); }
    .token-output { display:flex; flex-wrap:wrap; gap:6px; }
    .token-pill { padding:6px 10px; border-radius:999px; background:rgba(255,255,255,0.02); font-family:var(--mono); font-size:12px; border:1px solid rgba(255,255,255,0.02); }
    #plot, #highdim-plot, #live-plot, .heatmap { height:360px; min-height:220px; border-radius:10px; overflow:hidden; background:transparent; border:1px solid rgba(255,255,255,0.03); }
    #live-plot { height:220px; }
    .status-bar { position:fixed; left:0;right:0;bottom:0; display:flex; align-items:center; justify-content:space-between; padding:10px 18px; background:linear-gradient(180deg, rgba(2,6,23,0.9), rgba(2,6,23,0.98)); color:var(--muted); border-top:1px solid rgba(255,255,255,0.02); font-size:13px; z-index:9999; }
    .logpane { max-height:200px; overflow:auto; background:rgba(0,0,0,0.06); padding:8px; border-radius:8px; font-family:var(--mono); font-size:12px; color:#cfe; }
    pre.mathml { background: rgba(0,0,0,0.06); padding:8px; border-radius:8px; overflow:auto; font-family:var(--mono); font-size:12px; color:#dfe; max-height:180px; }
    .explain { font-size:13px; color:#dfe; line-height:1.45; }
    .badge { font-family:var(--mono); font-size:12px; padding:4px 8px; border-radius:999px; background:rgba(255,255,255,0.02); }
    @media (max-width: 980px) { .container { grid-template-columns: 1fr; padding-bottom:180px; } #plot { height:320px; } #highdim-plot { height:260px; } #live-plot { height:200px; } }
  </style>
</head>
<body>
  <header class="container" style="max-width:1200px;">
    <div class="brand">
      <div class="logo">EMB</div>
      <div>
        <h1>Interactive Tokenizer & Embedding Trainer — Didactic</h1>
        <p class="lead">Ziel: jeder, der ungefähr weiß, wie ein neuronales Netz funktioniert, soll verstehen, was Encodings bedeuten.</p>
      </div>
    </div>
    <div style="display:flex;gap:8px;align-items:center;">
      <div class="badge" id="ui-status">idle</div>
      <button id="run-tests">Run tests</button>
    </div>
  </header>

  <main class="container" aria-live="polite">
    <!-- left column -->
    <section class="panel">
      <div style="display:flex;justify-content:space-between;align-items:center;">
        <strong>Eingabe & Tokenizer</strong>
        <small class="muted">Live-Tokenisierung</small>
      </div>

      <div class="grid" style="margin-top:8px;">
        <div>
          <label for="input-text">Haupttext</label>
          <textarea id="input-text" rows="6" placeholder="Gib Text ein..."></textarea>
        </div>

        <div style="display:flex;gap:8px;align-items:flex-end;">
          <div style="flex:1;">
            <label for="tokenizer-type">Tokenizer</label>
            <select id="tokenizer-type"><option value="whitespace">Whitespace</option><option value="comma">Comma</option><option value="regex">Regex</option><option value="ngram" selected>n-gram</option><option value="char">char</option></select>
          </div>
          <div style="width:140px;">
            <label for="ngram-n">n</label>
            <input id="ngram-n" type="number" min="1" value="2" />
          </div>
          <div style="width:160px;">
            <label for="ngram-mode">n-gram Mode</label>
            <select id="ngram-mode"><option value="word" selected>word n-grams</option><option value="char">character n-grams</option></select>
          </div>
        </div>

        <div>
          <label>Token-Vorschau</label>
          <div class="token-output" id="token-preview"></div>
        </div>

        <div style="display:flex;gap:8px;align-items:center;justify-content:space-between;">
          <div class="muted">Tokens: <strong id="stat-token-count">0</strong> • Unique: <strong id="stat-unique-count">0</strong></div>
          <div style="display:flex;gap:6px;">
            <button id="btn-tokenize" class="ghost">Tokenize</button>
            <button id="btn-build-vocab">Build vocab</button>
            <button id="btn-clear" class="ghost">Clear</button>
          </div>
        </div>
      </div>
    </section>

    <!-- right column: controls and internals -->
    <aside class="sidebar">
      <div class="panel">
        <div style="display:flex;justify-content:space-between;align-items:center;">
          <strong>Embedding & Training</strong>
          <small class="muted">Konfiguration</small>
        </div>
        <div class="grid" style="margin-top:8px;">
          <label for="embedding-dim">Embedding Länge (Dim)</label>
          <input id="embedding-dim" type="number" min="1" value="8" />
          <label for="visual-dims">Visual dims (1-3 zeigen im Hauptplot; >3 nutzt High-Dim Ansicht)</label>
          <select id="visual-dims"><option value="1">1</option><option value="2">2</option><option value="3">3</option><option value="4">4+</option></select>
          <label for="visual-mode">High-Dim Visualisierung</label>
          <select id="visual-mode"><option value="auto" selected>auto (parallel coords + pca + heatmap)</option><option value="parallel">parallel coordinates</option><option value="pca">PCA 2D</option><option value="pairwise">Pairwise scatter matrix</option><option value="heatmap">Correlation heatmap</option></select>
          <label for="learning-rate">Learning rate</label>
          <input id="learning-rate" type="number" min="1e-6" step="1e-4" value="0.01" />
          <label for="optimizer-type">Optimizer</label>
          <select id="optimizer-type"><option value="sgd">SGD</option><option value="adam" selected>Adam</option></select>
          <label for="batch-size">Batch size</label>
          <input id="batch-size" type="number" min="1" value="8" />
          <label for="epochs">Epochs</label>
          <input id="epochs" type="number" min="1" value="6" />
          <div style="display:flex;gap:8px;">
            <button id="btn-create-model">Create model</button>
            <button id="btn-train">Train</button>
          </div>
          <div>
            <label>Model summary</label>
            <pre id="model-summary" style="font-family:var(--mono);font-size:12px;white-space:pre-wrap;max-height:140px;overflow:auto;"></pre>
          </div>
        </div>
      </div>

      <div class="panel">
        <div style="display:flex;justify-content:space-between;align-items:center;">
          <strong>Live während Training</strong>
          <small class="muted">separate Ansicht</small>
        </div>
        <div style="margin-top:8px;">
          <label for="live-text">Live Text</label>
          <input id="live-text" placeholder="Text zur Live-Visualisierung..." />
          <div style="display:flex;gap:8px;margin-top:8px;">
            <button id="btn-live-toggle" class="ghost">Live (off)</button>
          </div>
          <div id="live-plot" style="margin-top:8px;"></div>
        </div>
      </div>

      <div class="panel">
        <div style="display:flex;justify-content:space-between;align-items:center;">
          <strong>Internals & Tensoren</strong>
          <small class="muted">MathML & Heatmaps</small>
        </div>
        <div style="margin-top:8px;">
          <div class="explain" style="margin-bottom:8px;">
            <strong>Was du hier siehst</strong>
            <p>Wähle "Show embedding matrix" oder "Show model internals". Matrizen werden <em>als gerenderte MathML</em> angezeigt (falls der Browser MathML unterstützt) und zusätzlich als Heatmap, damit du Muster wie ähnliche Vektoren oder starke/negative Werte visuell erkennen kannst.</p>
          </div>
          <div style="display:flex;gap:8px;">
            <button id="btn-show-emb-math" class="ghost">Show embedding matrix</button>
            <button id="btn-show-model-internals" class="ghost">Show model internals</button>
          </div>
          <div style="margin-top:8px;">
            <div id="tensor-meta" class="muted"></div>
            <div id="tensor-mathml-render" style="margin-top:8px;"></div>
            <div id="tensor-heatmap" class="heatmap" style="margin-top:8px;"></div>
            <div id="model-internals-render" style="margin-top:8px;"></div>
          </div>
        </div>
      </div>

      <div class="panel">
        <div style="display:flex;justify-content:space-between;align-items:center;">
          <strong>Didaktische Erklärungen</strong>
          <small class="muted">Warum Encodings wichtig sind</small>
        </div>
        <div style="margin-top:8px;" class="explain">
          <ol>
            <li><strong>Was ist ein Encoding?</strong> — Ein Encoding (Embedding) ist ein Vektor, der ein Token (Wort/Char/NG-gram) in einem kontinuierlichen Raum darstellt. Ähnliche Token haben ähnliche Vektoren.</li>
            <li><strong>Warum Vektoren?</strong> — Vektoren erlauben algebraische Operationen (z.B. Ähnlichkeit, Mittelwert), die semantische Beziehungen sichtbar machen.</li>
            <li><strong>Was zeigt die Matrix?</strong> — Jede Zeile der Embedding-Matrix ist das Encoding für ein Vocabulary-Element. Die Heatmap zeigt Muster: dunkle/helle Bereiche signalisieren hohe/geringe Werte; ähnliche Zeilen deuten auf ähnliche Bedeutungen.</li>
            <li><strong>Was sind Kernel / Gewichte?</strong> — Kernel in Dense/Conv-Schichten sind die Transformationen, die aus Encodings Vorhersagen machen. Visualisierte Kernel helfen zu verstehen, welche Dimensionskombinationen wichtig sind.</li>
            <li><strong>Interpretiere die Grafiken:</strong> Parallel Coordinates zeigen Profilmuster über viele Dimensionen. PCA/Pairwise macht hohe Dimmensionen sichtbar, indem ähnliche Punkte zusammengezogen werden. Heatmaps zeigen Korrelationen.</li>
          </ol>
          <p>Am Ende solltest du erkennen: Encodings sind numerische Repräsentationen — die Visualisierungen helfen zu sehen, welche Token nahe beieinander liegen und welche Dimensionsachsen (Features) stark variieren.</p>
        </div>
      </div>

      <div class="panel">
        <div style="display:flex;justify-content:space-between;align-items:center;">
          <strong>Logs</strong>
          <small class="muted">Konsole</small>
        </div>
        <div class="logpane" id="logpane" style="margin-top:8px;"></div>
      </div>
    </aside>

    <!-- full-width visualization area -->
    <section class="panel" style="grid-column: 1 / -1;">
      <div style="display:flex;justify-content:space-between;align-items:center;">
        <strong>Haupt-Visualisierung</strong>
        <small class="muted">1/2/3D im Hauptplot — >3D in separatem High-Dim Bereich</small>
      </div>
      <div style="display:grid;grid-template-columns: 1fr 420px; gap:12px; margin-top:12px;">
        <div>
          <div id="plot"></div>
          <div style="display:flex;gap:8px;justify-content:space-between;margin-top:8px;">
            <div class="muted">Hauptplot — transparenter Hintergrund</div>
            <div style="display:flex;gap:6px;">
              <button id="btn-export-emb" class="ghost">Export embeddings</button>
              <button id="btn-reset" class="ghost">Reset model</button>
            </div>
          </div>
        </div>

        <div>
          <div style="display:flex;justify-content:space-between;align-items:center;">
            <strong>High-Dim Ansicht</strong>
            <small class="muted">Parallel coords / PCA / Pairwise / Heatmap</small>
          </div>
          <div id="highdim-plot" style="margin-top:8px;"></div>
        </div>
      </div>
    </section>
  </main>

  <div class="status-bar" role="status" aria-live="polite">
    <div id="status-last" class="muted">idle</div>
    <div class="muted" id="status-meta">logs: <span id="log-count">0</span> | emb size: <span id="status-emb-size">0</span></div>
  </div>

  <script>
    "use strict";
    (function () {
      // Utilities
      const $ = s => document.querySelector(s);
      const $$ = s => Array.from(document.querySelectorAll(s));
      let logBuffer = [];
      function pushLog(level, message) {
        const entry = { time: new Date().toISOString(), level, message: String(message) };
        logBuffer.push(entry);
        if (logBuffer.length > 1000) logBuffer.shift();
        renderLogs();
        try { $("#status-last").textContent = `[${level}] ${message.split("\\n")[0]}`; $("#ui-status").textContent = level; } catch (e) {}
      }
      function renderLogs() {
        const el = $("#logpane");
        if (!el) return;
        el.innerHTML = logBuffer.slice(-80).map(e => `<div><small style="color:var(--muted)">[${e.time}]</small> <strong>${e.level}</strong> ${escapeHtml(e.message)}</div>`).join("");
        el.scrollTop = el.scrollHeight;
        $("#log-count").textContent = logBuffer.length;
      }
      function escapeHtml(s) { return String(s).replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;"); }

      // Capture console (non-invasive)
      (function () {
        const methods = ["log","info","warn","error"];
        methods.forEach(m => {
          const orig = console[m].bind(console);
          console[m] = function(...args) {
            try { pushLog(m, args.map(a => (a && a.stack) ? a.stack : (typeof a === "object" ? JSON.stringify(a) : String(a))).join(" ")); } catch (e) {}
            orig(...args);
          };
        });
      })();

      // Tokenizers
      const Tokenizers = (function () {
        function whitespaceTokenizer(text) { if (!text) return []; return text.split(/\s+/).filter(Boolean); }
        function commaTokenizer(text) { if (!text) return []; return text.split(",").map(s => s.trim()).filter(Boolean); }
        function regexTokenizer(text, opts) { if (!text) return []; const pattern = (opts && opts.pattern) || "\\b\\w+\\b"; try { const re = new RegExp(pattern,"g"); return text.match(re) || []; } catch (e) { console.warn("regex invalid", e); return []; } }
        function ngramTokenizer(text, opts) {
          if (!text) return [];
          const n = Math.max(1, (opts && parseInt(opts.n,10)) || 2);
          const mode = (opts && opts.mode) || "word";
          if (mode === "char") {
            const letters = Array.from(text.replace(/\s+/g,""));
            const out = [];
            for (let i=0;i<=letters.length-n;i++) out.push(letters.slice(i,i+n).join(""));
            return out;
          } else {
            const words = text.split(/\s+/).filter(Boolean);
            const out = [];
            for (let i=0;i<=words.length-n;i++) out.push(words.slice(i,i+n).join("_"));
            return out;
          }
        }
        function charTokenizer(text) { if (!text) return []; return Array.from(text.replace(/\s+/g,"")); }
        function buildTokenizer(type, opts) {
          switch(type) {
            case "whitespace": return t => whitespaceTokenizer(t,opts);
            case "comma": return t => commaTokenizer(t,opts);
            case "regex": return t => regexTokenizer(t,opts);
            case "ngram": return t => ngramTokenizer(t,opts);
            case "char": return t => charTokenizer(t,opts);
            default: return t => whitespaceTokenizer(t,opts);
          }
        }
        return { buildTokenizer, ngramTokenizer };
      })();

      // Vocab
      const Vocab = (function() {
        let tokenToId = {};
        let idToToken = [];
        function buildFromTokens(tokens) {
          tokenToId = {}; idToToken = [];
          tokens.forEach(t => { if (!(t in tokenToId)) { tokenToId[t] = idToToken.length; idToToken.push(t); } });
          console.info("vocab built", idToToken.length);
          return { tokenToId, idToToken };
        }
        function addTokens(tokens) { tokens.forEach(t => { if (!(t in tokenToId)) { tokenToId[t] = idToToken.length; idToToken.push(t); } }); }
        function size() { return idToToken.length; }
        function encode(tokens) { return tokens.map(t => { if (t in tokenToId) return tokenToId[t]; tokenToId[t] = idToToken.length; idToToken.push(t); return tokenToId[t]; }); }
        function decode(ids) { return ids.map(i => idToToken[i] || "<UNK>"); }
        function reset() { tokenToId = {}; idToToken = []; }
        function exportVocab() { return { tokenToId: Object.assign({}, tokenToId), idToToken: idToToken.slice() }; }
        return { buildFromTokens, addTokens, size, encode, decode, reset, exportVocab };
      })();

      // Trainer
      const Trainer = (function() {
        let model = null; let created=false; let lastEmbedding=null;
        async function createModel(params) {
          try {
            const inputDim = parseInt(params.inputDim,10);
            const embeddingDim = parseInt(params.outputDim || params.embeddingDim,10);
            if (!Number.isInteger(inputDim) || inputDim<=0) throw new Error("invalid inputDim");
            if (!Number.isInteger(embeddingDim) || embeddingDim<=0) throw new Error("invalid embeddingDim");
            const input = tf.input({shape:[1], dtype:"int32", name:"token_input"});
            const emb = tf.layers.embedding({ inputDim: inputDim, outputDim: embeddingDim, inputLength: 1, name: "embedding" });
            const embedOut = emb.apply(input);
            const flat = tf.layers.flatten().apply(embedOut);
            const decoder = tf.layers.dense({ units: inputDim, activation: "softmax", name: "decoder" }).apply(flat);
            const m = tf.model({ inputs: input, outputs: decoder, name:"embed_model" });
            const opt = (params.optimizer === "sgd") ? tf.train.sgd(params.learningRate || 0.01) : tf.train.adam(params.learningRate || 0.01);
            m.compile({ optimizer: opt, loss: "sparseCategoricalCrossentropy", metrics: ["accuracy"] });
            model = m; created=true;
            try { let s=""; m.summary(80,{print: (l)=> s+=l+"\n" }); $("#model-summary").textContent = s; } catch(e) {}
            return m;
          } catch (err) { console.error("createModel", err); throw err; }
        }
        function hasModel(){ return created && model; }
        function getEmbeddingMatrix() {
          if (!hasModel()) return null;
          try { const layer = model.getLayer("embedding"); const weights = layer.getWeights(); if (weights && weights.length>0) { lastEmbedding = weights[0]; return lastEmbedding; } return null; } catch (e) { console.error(e); return null; }
        }
        async function trainOnDataset(encodedTokens, params, hooks) {
          if (!hasModel()) throw new Error("no model");
          if (!Array.isArray(encodedTokens) || encodedTokens.length===0) return;
          const N = encodedTokens.length;
          const xsArr = encodedTokens.map(v => [parseInt(v,10)]);
          const ysArr = encodedTokens.map(v => parseInt(v,10));
          const xs = tf.tensor2d(xsArr,[N,1],"int32");
          const ys = tf.tensor1d(ysArr,"float32");
          await model.fit(xs, ys, {
            batchSize: params.batchSize || 8,
            epochs: params.epochs || 1,
            shuffle: true,
            callbacks: {
              onBatchEnd: async (batch, logs) => { if (hooks && hooks.onBatchEnd) await hooks.onBatchEnd(batch, logs); },
              onEpochEnd: async (epoch, logs) => { if (hooks && hooks.onEpochEnd) await hooks.onEpochEnd(epoch, logs); }
            }
          });
          xs.dispose(); ys.dispose();
        }
        function resetModel(){ try { if (model) { model.dispose(); model=null; created=false; lastEmbedding=null; $("#model-summary").textContent=""; } } catch(e){} }
        async function readModelInternals() {
          if (!hasModel()) return null;
          const layers = model.layers || [];
          const out = [];
          for (let i=0;i<layers.length;i++){
            const layer = layers[i];
            const weightTensors = layer.getWeights ? layer.getWeights() : [];
            const weightObjects = (layer.weights || []).slice();
            const ws = [];
            for (let j=0;j<weightTensors.length;j++){
              const wt = weightTensors[j];
              const name = (weightObjects[j] && weightObjects[j].name) ? weightObjects[j].name : `w_${j}`;
              ws.push({ name, tensor: wt });
            }
            out.push({ name: layer.name || `layer_${i}`, className: layer.getClassName ? layer.getClassName() : "Layer", weights: ws });
          }
          return out;
        }
        return { createModel, hasModel, getEmbeddingMatrix, trainOnDataset, resetModel, readModelInternals };
      })();

      // MathML helper
      async function tensorToMathML(tensor) {
        if (!tensor) return { mathml: "<math></math>", meta: "null" };
        let arr;
        try { if (typeof tensor.arraySync === "function") arr = tensor.arraySync(); else arr = await tensor.array(); } catch(e) { try { arr = await tensor.array(); } catch(e2) { arr = null; } }
        const shape = tensor.shape ? tensor.shape.slice() : (Array.isArray(arr) ? (Array.isArray(arr[0]) ? [arr.length, arr[0].length] : [arr.length]) : []);
        const dtype = tensor.dtype || "float32";
        const size = tensor.size || (Array.isArray(arr) ? (function count(a){ if (!Array.isArray(a)) return 1; return a.reduce((s,x)=>s+count(x),0); })(arr) : 0);
        function rowToTR(r) { if (!Array.isArray(r)) return `<mtr><mtd><mn>${escapeHtml(String(r))}</mn></mtd></mtr>`; return `<mtr>${r.map(c=>`<mtd><mn>${escapeHtml(String(c))}</mn></mtd>`).join("")}</mtr>`; }
        let mtable = "";
        if (Array.isArray(arr) && Array.isArray(arr[0])) {
          mtable = `<mtable>${arr.map(r=> Array.isArray(r) ? `<mtr>${r.map(c=>`<mtd><mn>${escapeHtml(String(c))}</mn></mtd>`).join("")}</mtr>` : `<mtr><mtd><mn>${escapeHtml(String(r))}</mn></mtd></mtr>`).join("")}</mtable>`;
        } else if (Array.isArray(arr)) {
          mtable = `<mtable><mtr>${arr.map(c=>`<mtd><mn>${escapeHtml(String(c))}</mn></mtd>`).join("")}</mtr></mtable>`;
        } else {
          mtable = `<mtable><mtr><mtd><mn>${escapeHtml(String(arr))}</mn></mtd></mtr></mtable>`;
        }
        const mathml = `<math xmlns="http://www.w3.org/1998/Math/MathML">${mtable}</math>`;
        const meta = `shape: [${shape.join(", ")}], dtype: ${dtype}, size: ${size}`;
        return { mathml, meta, array: arr, shape, dtype, size };
      }

      // Visualization helpers
      let lastPlotLayout = null;
      const Visual = (function(){
        async function extractEmbeddings(embVar) {
          if (!embVar) throw new Error("no emb var");
          return await embVar.array();
        }
        async function projectPCA(embeddings, k) {
          if (!embeddings || embeddings.length===0) return [];
          const matrix = tf.tensor2d(embeddings);
          const mean = tf.mean(matrix,0);
          const centered = tf.sub(matrix, mean);
          const cov = tf.matMul(centered.transpose(), centered);
          function powerIteration(mat, iterations) {
            let b = tf.randomUniform([mat.shape[0],1]);
            for (let i=0;i<iterations;i++){ b = tf.matMul(mat,b); const norm = tf.norm(b); b = tf.div(b,norm); }
            return b;
          }
          const vectors = [];
          let M = cov;
          for (let d=0; d<k; d++){ const v = powerIteration(M, 60); vectors.push(v); const lambda = tf.matMul(tf.transpose(v), tf.matMul(M, v)); const outer = tf.matMul(v, tf.transpose(v)); M = tf.sub(M, tf.mul(lambda, outer)); }
          const projection = tf.concat(vectors,1);
          const reduced = tf.matMul(centered, projection);
          const res = reduced.arraySync();
          matrix.dispose(); mean.dispose(); centered.dispose(); cov.dispose(); projection.dispose(); reduced.dispose();
          return res;
        }

        // Primary visualize function: 1/2/3D on #plot; >3 goes to #highdim-plot
        async function visualizePoints(points, labels, dimsRequested, mode, sliceAxes) {
          try {
            if (!Array.isArray(points) || points.length===0) {
              Plotly.react("plot", [{ x:[], y:[], mode:"markers" }], layoutTransparent("Empty"));
              return;
            }
            const n = points.length; const d = (points[0]||[]).length||0;
            // choose where to draw
            if (d >= dimsRequested && dimsRequested<=3 && dimsRequested<=3) {
              // main plot
              if (dimsRequested===1) {
                const x = points.map(p=>p[0]); const y = points.map(()=>0);
                const data = [{ x, y, text: labels, mode: "markers+text", type:"scatter", marker:{size:9}, textposition:"top center" }];
                const lay = layoutTransparent("1D embeddings");
                Plotly.react("plot", data, lay);
                lastPlotLayout = lay;
                return;
              } else if (dimsRequested===2) {
                const data = [{ x: points.map(p=>p[0]), y: points.map(p=>p[1]), text: labels, mode: "markers+text", type:"scatter", marker:{size:8} }];
                const lay = layoutTransparent("2D embeddings");
                Plotly.react("plot", data, lay);
                lastPlotLayout = lay;
                return;
              } else {
                const data = [{ x: points.map(p=>p[0]), y: points.map(p=>p[1]), z: points.map(p=>p[2]), text: labels, mode:"markers", type:"scatter3d", marker:{size:4} }];
                const lay = layoutTransparent("3D embeddings", {scene:{bgcolor:"rgba(0,0,0,0)"}});
                Plotly.react("plot", data, lay);
                lastPlotLayout = lay;
                return;
              }
            }

            // High-dim: render only in #highdim-plot (no overlap)
            const target = "highdim-plot";

            if (mode === "pairwise") {
              // create pairwise scatter matrix for first min(6,d) dims
              const dims = Math.min(6, d);
              const figData = [];
              const figLayout = layoutTransparent("Pairwise scatter matrix");
              // For simplicity, perform PCA to 3 dims and show scatter matrix of those dims
              const pca = await projectPCA(points, Math.min(3,d));
              const used = pca[0] ? pca[0].length : 2;
              const dimsLabels = Array.from({length:used},(_,i)=>`PC${i+1}`);
              // build scatter traces for combos
              // Plotly does not have a native scatter-matrix without using plotly.express; emulate by small subplots is heavy.
              // Instead show two visuals: PCA scatter and correlation heatmap
              const sc = { x: pca.map(r=>r[0]), y: pca.map(r=>r[1]), mode:"markers", type:"scatter", marker:{size:6}, text: labels };
              const corr = correlationMatrix(points);
              const heat = { z:corr.z, x:corr.x, y:corr.y, type:"heatmap", showscale:true };
              Plotly.react(target, [sc, heat], Object.assign({}, figLayout, {grid:{rows:2, columns:1, subplots:[["xy"],["xy2"]]}, xaxis:{domain:[0,1], anchor:"y"}, yaxis:{domain:[0.55,1], anchor:"x"}, xaxis2:{domain:[0,1], anchor:"y2"}, yaxis2:{domain:[0,0.45], anchor:"x2"}}));
              lastPlotLayout = figLayout;
              return;
            }

            if (mode === "heatmap") {
              const corr = correlationMatrix(points);
              const h = { z:corr.z, x:corr.x, y:corr.y, type:"heatmap", colorscale:"Viridis" };
              const lay = layoutTransparent("Correlation heatmap");
              Plotly.react(target, [h], lay);
              lastPlotLayout = lay;
              return;
            }

            if (mode === "pca") {
              const p = await projectPCA(points, 2);
              const data = [{ x: p.map(r=>r[0]), y: p.map(r=>r[1]), text: labels, mode:"markers+text", type:"scatter", marker:{size:8} }];
              const lay = layoutTransparent("PCA 2D");
              Plotly.react(target, data, lay);
              lastPlotLayout = lay;
              return;
            }

            // default: parallel coords + PCA small
            {
              const parDimensions = [];
              for (let dim=0; dim<d; dim++) {
                const values = points.map(p=>p[dim]);
                parDimensions.push({ label:`dim${dim}`, values, range:[Math.min(...values), Math.max(...values)] });
              }
              const parTrace = { type:"parcoords", line:{color:Array.from({length:n},(_,i)=>i), colorscale:"Turbo"}, dimensions:parDimensions, domain:{x:[0,1], y:[0.45,1]} };
              const pcaSmall = await projectPCA(points, 2);
              const scatter = { x: pcaSmall.map(r=>r[0]), y: pcaSmall.map(r=>r[1]), text: labels, mode:"markers", type:"scatter", marker:{size:6}, xaxis:"x2", yaxis:"y2" };
              const layout = layoutTransparent("Parallel Coordinates + PCA (small)");
              Plotly.react(target, [parTrace, scatter], Object.assign({}, layout, {xaxis2:{domain:[0,1]}, yaxis2:{domain:[0,0.45]}}));
              lastPlotLayout = layout;
              return;
            }

          } catch (err) { console.error("visualizePoints", err); pushLog("error", "visualizePoints: "+err.message); }
        }

        function layoutTransparent(title, extras) {
          const base = { title, margin:{t:30}, paper_bgcolor:"rgba(0,0,0,0)", plot_bgcolor:"rgba(0,0,0,0)", font:{color:"#e6eef6"} };
          if (extras) Object.assign(base, extras);
          return base;
        }

        function correlationMatrix(points) {
          const d = points[0].length;
          const x = Array.from({length:d},(_,i)=>`dim${i}`);
          const z = Array.from({length:d}, (_,i) => Array.from({length:d}, (_,j) => {
            const xi = points.map(p=>p[i]);
            const xj = points.map(p=>p[j]);
            const mean = arr => arr.reduce((s,v)=>s+v,0)/arr.length;
            const cov = (a,b)=>{ const ma=mean(a), mb=mean(b); let s=0; for (let k=0;k<a.length;k++) s += (a[k]-ma)*(b[k]-mb); return s/(a.length-1||1); };
            const std = a => Math.sqrt(cov(a,a)||1e-8);
            return cov(xi,xj)/(std(xi)*std(xj)+1e-8);
          }));
          return { x, y: x.slice(), z };
        }

        return { extractEmbeddings, visualizePoints, projectPCA };
      })();

      // UI wiring
      function initUI() {
        try {
          const inputText = $("#input-text");
          const tokenizerType = $("#tokenizer-type");
          const ngramN = $("#ngram-n");
          const ngramMode = $("#ngram-mode");
          const tokenPreview = $("#token-preview");
          let liveTokenizer = Tokenizers.buildTokenizer(tokenizerType.value, { n: parseInt(ngramN.value,10), mode: ngramMode.value });

          function refreshTokenizer() { liveTokenizer = Tokenizers.buildTokenizer(tokenizerType.value, { n: Math.max(1,parseInt(ngramN.value,10)), mode: ngramMode.value }); tokenizeAndPreview(); }

          tokenizerType.addEventListener("change", refreshTokenizer);
          ngramN.addEventListener("input", refreshTokenizer);
          ngramMode.addEventListener("change", refreshTokenizer);
          inputText.addEventListener("input", () => tokenizeAndPreview(true));
          $("#btn-tokenize").addEventListener("click", ()=> tokenizeAndPreview(true));
          $("#btn-build-vocab").addEventListener("click", ()=>{
            const toks = tokenizeAndPreview(true);
            Vocab.buildFromTokens(toks);
            $("#stat-vocab-size") && ($("#stat-vocab-size").textContent = Vocab.size());
            pushLog("info", "vocab built size="+Vocab.size());
          });
          $("#btn-clear").addEventListener("click", ()=> { inputText.value=""; tokenizeAndPreview(true); Vocab.reset(); $("#stat-vocab-size") && ($("#stat-vocab-size").textContent = Vocab.size()); });

          $("#btn-create-model").addEventListener("click", async () => {
            try {
              const vocabSize = Math.max(1, Vocab.size() || 4);
              const embeddingDim = Math.max(1, parseInt($("#embedding-dim").value,10) || 8);
              const optimizer = $("#optimizer-type").value;
              const lr = parseFloat($("#learning-rate").value) || 0.01;
              const m = await Trainer.createModel({ inputDim: vocabSize, outputDim: embeddingDim, optimizer, learningRate: lr });
              $("#status-emb-size").textContent = `${vocabSize}×${embeddingDim}`;
              pushLog("info","created model");
            } catch (err) { pushLog("error","create model failed: "+err.message); }
          });

          $("#btn-train").addEventListener("click", async () => {
            try {
              if (!Trainer.hasModel()) { await $("#btn-create-model").click(); }
              const enc = Vocab.encode(tokenizeAndPreview(true));
              if (!enc || enc.length===0) { pushLog("warn","no tokens to train"); return; }
              const params = { batchSize: parseInt($("#batch-size").value,10)||8, epochs: parseInt($("#epochs").value,10)||1 };
              const hooks = {
                onBatchEnd: async (batch, logs) => {
                  try {
                    const embVar = Trainer.getEmbeddingMatrix();
                    if (!embVar) return;
                    const raw = await Visual.extractEmbeddings(embVar);
                    const labels = Vocab.exportVocab().idToToken;
                    const dimsReq = parseInt($("#visual-dims").value,10);
                    const mode = $("#visual-mode").value;
                    await Visual.visualizePoints(raw, labels, dimsReq, mode, null);
                    // live text
                    if (liveMode) {
                      const s = $("#live-text").value || "";
                      const tok = Tokenizers.buildTokenizer($("#tokenizer-type").value, { n: Math.max(1,parseInt($("#ngram-n").value,10)), mode: $("#ngram-mode").value });
                      const toks = tok(s);
                      const vocab = Vocab.exportVocab();
                      const allEmb = await (Trainer.getEmbeddingMatrix()).array();
                      const selected = toks.map(t => { const id = (t in vocab.tokenToId) ? vocab.tokenToId[t] : -1; if (id>=0 && id<allEmb.length) return allEmb[id]; return new Array(allEmb[0].length).fill(0); });
                      if (selected.length>0) {
                        const p = await Visual.projectPCA(selected, 2);
                        Plotly.react("live-plot", [{ x: p.map(r=>r[0]), y: p.map(r=>r[1]), text: toks, mode:"markers+text", type:"scatter" }], { title: "Live probe", paper_bgcolor:"rgba(0,0,0,0)", plot_bgcolor:"rgba(0,0,0,0)", font:{color:"#e6eef6"} });
                      }
                    }
                  } catch (e) { console.error("onBatchEnd",e); }
                }
              };
              await Trainer.trainOnDataset(enc, params, hooks);
              pushLog("info","training finished");
            } catch (err) { pushLog("error","train failed: "+err.message); }
          });

          $("#btn-probe") && $("#btn-probe").addEventListener("click", probeNow);
          $("#btn-export-emb").addEventListener("click", async () => {
            try {
              const emb = Trainer.getEmbeddingMatrix();
              if (!emb) { pushLog("warn","no embedding"); return; }
              const arr = await emb.array();
              console.log("embeddings:", Vocab.exportVocab().idToToken, arr);
              alert("Embeddings in console.");
            } catch (e) { console.error(e); }
          });

          $("#btn-reset").addEventListener("click", () => { Trainer.resetModel(); $("#status-emb-size").textContent="0"; pushLog("info","model reset"); });

          $("#btn-live-toggle").addEventListener("click", () => { liveMode = !liveMode; $("#btn-live-toggle").textContent = liveMode ? "Live (on)" : "Live (off)"; });

          $("#btn-show-emb-math").addEventListener("click", async () => {
            try {
              const emb = Trainer.getEmbeddingMatrix();
              if (!emb) { $("#tensor-meta").textContent = "No embedding available"; $("#tensor-mathml-render").innerHTML = ""; $("#tensor-heatmap").innerHTML=""; return; }
              const res = await tensorToMathML(emb);
              $("#tensor-meta").textContent = res.meta;
              // Insert MathML raw so browsers render it (if supported)
              const renderEl = $("#tensor-mathml-render");
              renderEl.innerHTML = ""; const wrapper = document.createElement("div"); wrapper.innerHTML = res.mathml; renderEl.appendChild(wrapper);
              // heatmap
              try {
                const z = (res.array && Array.isArray(res.array)) ? res.array : [[]];
                Plotly.react("tensor-heatmap", [{ z, type:"heatmap", colorscale:"Viridis" }], { title: "Embedding heatmap", paper_bgcolor:"rgba(0,0,0,0)", plot_bgcolor:"rgba(0,0,0,0)", font:{color:"#e6eef6"} });
              } catch(e) { console.warn("heatmap failed", e); }
            } catch (e) { console.error(e); }
          });

          $("#btn-show-model-internals").addEventListener("click", async () => {
            try {
              const internals = await Trainer.readModelInternals();
              const container = $("#model-internals-render"); container.innerHTML = "";
              if (!internals) { container.textContent = "No model internals"; return; }
              for (let i=0;i<internals.length;i++){
                const li = internals[i];
                const hdr = document.createElement("div"); hdr.innerHTML = `<strong>Layer: ${escapeHtml(li.name)} (${escapeHtml(li.className)})</strong>`; container.appendChild(hdr);
                for (let j=0;j<li.weights.length;j++){
                  const wt = li.weights[j];
                  const block = document.createElement("div"); block.style.marginTop="6px";
                  block.innerHTML = `<div style="font-family:var(--mono);font-size:12px;color:var(--muted)">weight: ${escapeHtml(wt.name)}</div>`;
                  try {
                    const res = await tensorToMathML(wt.tensor);
                    const mdiv = document.createElement("div"); mdiv.innerHTML = res.mathml;
                    block.appendChild(mdiv);
                    // add mini heatmap
                    const heatId = `heat-${i}-${j}-${Date.now()}`;
                    const heatDiv = document.createElement("div"); heatDiv.id = heatId; heatDiv.className = "heatmap"; heatDiv.style.height = "140px"; heatDiv.style.marginTop="6px";
                    block.appendChild(heatDiv);
                    const z = (res.array && Array.isArray(res.array)) ? res.array : [[res.array]];
                    try { Plotly.react(heatId, [{ z, type:"heatmap", colorscale:"Viridis" }], { title: `${wt.name} heatmap`, paper_bgcolor:"rgba(0,0,0,0)", plot_bgcolor:"rgba(0,0,0,0)", font:{color:"#e6eef6"} }); } catch(e){ console.warn("plot heat error",e); }
                    container.appendChild(block);
                  } catch(e) { block.appendChild(document.createTextNode("error rendering weight")); container.appendChild(block); }
                }
              }
            } catch (e) { console.error(e); }
          });

          $("#run-tests").addEventListener("click", runTests);

        } catch (e) { console.error("initUI", e); }
      }

      function tokenizeAndPreview(force) {
        try {
          const text = $("#input-text").value || "";
          const type = $("#tokenizer-type").value;
          const n = Math.max(1, parseInt($("#ngram-n").value,10)||2);
          const mode = $("#ngram-mode").value;
          const tokenizer = Tokenizers.buildTokenizer(type, { n, mode });
          const toks = tokenizer(text);
          const preview = $("#token-preview"); preview.innerHTML = "";
          toks.forEach(t => { const el = document.createElement("div"); el.className="token-pill"; el.textContent = t; preview.appendChild(el); });
          $("#stat-token-count").textContent = toks.length; $("#stat-unique-count").textContent = Array.from(new Set(toks)).length;
          if (force) pushLog("info","tokenized "+toks.length+" tokens");
          return toks;
        } catch (e) { console.error(e); return []; }
      }

      async function probeNow() {
        try {
          const s = ($("#probe-text") && $("#probe-text").value) || "";
          const tokenizer = Tokenizers.buildTokenizer($("#tokenizer-type").value, { n: Math.max(1,parseInt($("#ngram-n").value,10)||2), mode: $("#ngram-mode").value });
          const toks = tokenizer(s);
          // show in preview if exist
          const preview = $("#probe-preview"); if (preview) { preview.innerHTML = ""; toks.forEach(t=>{ const d=document.createElement("div"); d.className="token-pill"; d.textContent=t; preview.appendChild(d); }); }
          if (Trainer.hasModel()) {
            const embVar = Trainer.getEmbeddingMatrix();
            const allEmb = await embVar.array();
            const vocab = Vocab.exportVocab();
            const selected = toks.map(t => { const id = (t in vocab.tokenToId)?vocab.tokenToId[t]:-1; return (id>=0 && id<allEmb.length)?allEmb[id]:new Array(allEmb[0].length).fill(0); });
            if (selected.length>0) {
              const p = await Visual.projectPCA(selected,2);
              Plotly.react("live-plot", [{ x: p.map(r=>r[0]), y: p.map(r=>r[1]), text:toks, mode:"markers+text", type:"scatter" }], { title:"Probe", paper_bgcolor:"rgba(0,0,0,0)", plot_bgcolor:"rgba(0,0,0,0)", font:{color:"#e6eef6"} });
            }
          }
        } catch (e) { console.error(e); }
      }

      // Test suite (adds checks for MathML render + transparent layout)
      async function runTests() {
        const results = [];
        console.group("Tests");
        try {
          // T1 whitespace tokenizer
          try { const t = Tokenizers.buildTokenizer("whitespace"); const out = t("a b c"); if (Array.isArray(out) && out.length===3) { results.push({name:"t_whitespace",ok:true}); } else { results.push({name:"t_whitespace",ok:false}); } } catch(e){ results.push({name:"t_whitespace",ok:false,err:e}); }

          // T2 ngram char
          try { const tn = Tokenizers.buildTokenizer("ngram",{n:2,mode:"char"}); const out = tn("ab cd"); if (Array.isArray(out) && out.length>=3 && out[0]==="ab") results.push({name:"t_ngram_char",ok:true}); else results.push({name:"t_ngram_char",ok:false}); } catch(e){ results.push({name:"t_ngram_char",ok:false,err:e}); }

          // T3 create model and show emb math
          try {
            Vocab.reset(); Vocab.buildFromTokens(["one","two","three","four"]);
            await Trainer.createModel({ inputDim: Vocab.size(), outputDim: 4, optimizer:"adam", learningRate:0.01 });
            const enc = Vocab.encode(["one","two","three","one"]);
            await Trainer.trainOnDataset(enc, { batchSize:2, epochs:1 }, {});
            // show embedding math into DOM
            await $("#btn-show-emb-math").click();
            // check DOM
            const mathEl = $("#tensor-mathml-render");
            const mathHas = mathEl && mathEl.innerHTML && mathEl.innerHTML.indexOf("<math") !== -1;
            results.push({ name: "t_emb_math_dom", ok: !!mathHas });
          } catch (e) { results.push({ name: "t_emb_math_dom", ok: false, err: e }); }

          // T4 visualizePoints uses transparent layout (lastPlotLayout set)
          try {
            const points = [[1,2,3],[2,3,4],[3,2,1]];
            await Visual.visualizePoints(points, ["a","b","c"], 4, "pca");
            const ok = lastPlotLayout && lastPlotLayout.paper_bgcolor && String(lastPlotLayout.paper_bgcolor).indexOf("rgba")!==-1;
            results.push({ name: "t_layout_transparent", ok: !!ok });
          } catch (e) { results.push({ name: "t_layout_transparent", ok: false, err: e }); }

          // report
          const passed = results.filter(r=>r.ok).length;
          console.log("Test results", results);
          alert(`Tests finished: ${passed}/${results.length} passed. Sieh Konsole für Details.`);
        } catch (e) {
          console.error("tests failed", e); alert("Tests encountered an error, check console.");
        } finally { console.groupEnd(); }
      }

      // startup
      let liveMode = false;
      (function main() {
        try {
          initUI();
          tokenizeAndPreview();
          Plotly.newPlot("plot", [{ x:[], y:[], mode:"markers" }], { title:"Embeddings", paper_bgcolor:"rgba(0,0,0,0)", plot_bgcolor:"rgba(0,0,0,0)", font:{color:"#e6eef6"} });
          Plotly.newPlot("highdim-plot", [{ x:[], y:[], mode:"markers" }], { title:"High-dim", paper_bgcolor:"rgba(0,0,0,0)", plot_bgcolor:"rgba(0,0,0,0)", font:{color:"#e6eef6"} });
          Plotly.newPlot("live-plot", [{ x:[], y:[], mode:"markers" }], { title:"Live probe", paper_bgcolor:"rgba(0,0,0,0)", plot_bgcolor:"rgba(0,0,0,0)", font:{color:"#e6eef6"} });
          pushLog("info","App ready");
        } catch (e) { console.error("init error", e); pushLog("error","init error "+e.message); }
      })();

    })();
  </script>
</body>
</html>
